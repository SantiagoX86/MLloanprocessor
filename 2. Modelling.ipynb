{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed58c5aa",
   "metadata": {},
   "source": [
    "# **Lenders Club ML Loan Processor**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6e1d7f",
   "metadata": {},
   "source": [
    "# Imports\n",
    "##### 1. Import Libraries\n",
    "##### 2. Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0fae17",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ae63753",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fa2f75",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5d3ae90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in cleaned data from previous notebook\n",
    "df = pd.read_csv('./data/cleaned_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e3174f",
   "metadata": {},
   "source": [
    "\n",
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8049b3ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8722750321985419"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Establish a baseline based on percentage of loans that are good\n",
    "baseline = len(df[df['loan_status']==1])/len(df)\n",
    "baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebe5f1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X and y\n",
    "X = df.drop(columns=['loan_status'])\n",
    "y = df['loan_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6b13772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state=23, test_size=.2, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203bc0fc",
   "metadata": {},
   "source": [
    "# Production Model Fitting and Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fbd3633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate GBClassifier\n",
    "gb = GradientBoostingClassifier(learning_rate=0.125, max_depth=2, n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3dea23f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(learning_rate=0.125, max_depth=2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit model\n",
    "gb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fcdedb4",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-8753a393b3bd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Cross Val Score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcvs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Programming\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programming\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    438\u001b[0m     \u001b[0mscorer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m     cv_results = cross_validate(estimator=estimator, X=X, y=y, groups=groups,\n\u001b[0m\u001b[0;32m    441\u001b[0m                                 \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'score'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m                                 \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programming\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programming\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    244\u001b[0m     parallel = Parallel(n_jobs=n_jobs, verbose=verbose,\n\u001b[0;32m    245\u001b[0m                         pre_dispatch=pre_dispatch)\n\u001b[1;32m--> 246\u001b[1;33m     results = parallel(\n\u001b[0m\u001b[0;32m    247\u001b[0m         delayed(_fit_and_score)(\n\u001b[0;32m    248\u001b[0m             \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscorers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programming\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1044\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1045\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1046\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programming\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    857\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programming\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    775\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 777\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    778\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programming\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programming\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programming\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programming\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programming\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Programming\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    591\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    594\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programming\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m    502\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    503\u001b[0m         \u001b[1;31m# fit the boosting stages\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 504\u001b[1;33m         n_stages = self._fit_stages(\n\u001b[0m\u001b[0;32m    505\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraw_predictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_rng\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    506\u001b[0m             sample_weight_val, begin_at_stage, monitor)\n",
      "\u001b[1;32mD:\\Programming\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[1;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[0;32m    559\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m             \u001b[1;31m# fit next stage of trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 561\u001b[1;33m             raw_predictions = self._fit_stage(\n\u001b[0m\u001b[0;32m    562\u001b[0m                 \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraw_predictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m                 random_state, X_csc, X_csr)\n",
      "\u001b[1;32mD:\\Programming\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[1;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 214\u001b[1;33m             tree.fit(X, residual, sample_weight=sample_weight,\n\u001b[0m\u001b[0;32m    215\u001b[0m                      check_input=False)\n\u001b[0;32m    216\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programming\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m   1245\u001b[0m         \"\"\"\n\u001b[0;32m   1246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1247\u001b[1;33m         super().fit(\n\u001b[0m\u001b[0;32m   1248\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1249\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programming\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    387\u001b[0m                                            min_impurity_split)\n\u001b[0;32m    388\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 389\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    390\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Cross Val Score\n",
    "cvs = cross_val_score(gb, X_train, y_train, cv=5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956430ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GB Feature Importance\n",
    "feat_imp = {k:v for k,v in list(zip(df.columns,gb.feature_importances_)) if v !=0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc16c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Prediction Probabilities\n",
    "pred_proba = gb.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bf2208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Predictions\n",
    "preds = gb.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eacd83c",
   "metadata": {},
   "source": [
    "# Analyzing Model\n",
    "##### 1. Analyze classification metrics for original model\n",
    "##### 2. Create Resulting dataframe of test data for further analysis of model\n",
    "##### 3. Create Dataframe of middle of the road loans that may have to be analyzed further by human underwriter\n",
    "##### 4. Create Dataframe of \"solid decision\" loans to analyze whether they can be safely determined by the model\n",
    "##### 5. Adjust model to decrease Type 1 errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51927f07",
   "metadata": {},
   "source": [
    "### Analyze classification metrics for original model\n",
    "Using Scikit-Learn.metrics, obtain confusion matrices, Accuracy scores, Recall score, Specificity score, Precision score, and F1 score and plot various graphs to visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90629f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Histogram of prediction probabilities\n",
    "fig, ax = plt.subplots(1,1, figsize=(15,10), facecolor='white')\n",
    "\n",
    "ax.set_title('Distribution of Prediction Probabilities', loc='center', size=35, pad=20)\n",
    "ax.hist(pred_proba[:,1],bins=20, color='#FEC683', edgecolor='#262F72')\n",
    "ax.set_xlabel('Predicted Probability Loan is Good', size=25)\n",
    "ax.set_ylabel('Number of Loans', size=25)\n",
    "plt.xticks(list(np.arange(0,1.05,.05)))\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b673e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate percentage of loans given a probability of >= .95\n",
    "len([pp for pp in pred_proba[:,1] if pp >=.95])/len(pred_proba[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8592ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix dataframe\n",
    "def conf_mat(actual,pred):\n",
    "    return pd.DataFrame(metrics.confusion_matrix(actual,pred),\n",
    "             columns=['pred bad', 'pred good'],\n",
    "             index=['actual bad', 'actual good'])\n",
    "conf_mat(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d8c196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to plot confusion matrix\n",
    "def plot_cm(actual, pred):\n",
    "    matrix = metrics.confusion_matrix(actual,pred)\n",
    "    fig = plt.figure(figsize=(15,10),facecolor='white')\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(matrix, cmap='Blues')\n",
    "    plt.title('Loan Confusion Matrix', size=35, pad=25)\n",
    "    plt.xlabel('Predictions', size=25, labelpad=15)\n",
    "    plt.ylabel('Actual', size=25, labelpad=15)\n",
    "    labels = ['Bad','Good']\n",
    "    ax.set_xticklabels(['']+labels, size=15)\n",
    "    ax.set_yticklabels(['']+labels, size=15)\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    mat = metrics.confusion_matrix(actual,pred)\n",
    "    for k,v in enumerate(mat.T):\n",
    "        for n,m in enumerate(v):\n",
    "            if m < len(pred)/2:\n",
    "                ax.text(k,n,m, color='#D87702', size=35, va='center', ha='center')\n",
    "            else:\n",
    "                ax.text(k,n,m, color='#FCC274', size=35, va='center', ha='center')\n",
    "    fig.colorbar(cax);\n",
    "    \n",
    "plot_cm(y_test,preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d55fbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot an ROC Curve\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test, pred_proba[:,1])\n",
    "\n",
    "plt.figure(figsize=(15,10), facecolor='white')\n",
    "\n",
    "plt.plot(fpr, tpr, color='#16447D', label='ROC Curve')\n",
    "plt.title('ROC Curve', size=35)\n",
    "plt.plot([0,1],[0,1],color='#D87702', label='Baseline')\n",
    "plt.xlabel('False Positive Rate', size=20)\n",
    "plt.ylabel('True Positive Rate', size=20)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a278864a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cl_metrics(actual,pred):\n",
    "    # Create variables for classification metrics\n",
    "    tn, fp, fn, tp = metrics.confusion_matrix(actual, pred).flatten()\n",
    "    print('Accuracy Score: ', round(metrics.accuracy_score(actual, pred),3))\n",
    "    print('Recall Score: ', round(metrics.recall_score(actual, pred),3))\n",
    "    print('Specificity Score: ', round(tn/(tn+fp),3))\n",
    "    print('Precision Score: ',round(metrics.precision_score(actual, pred),3))\n",
    "    print('F1 Score: ', round(metrics.f1_score(actual, pred),3))\n",
    "    \n",
    "cl_metrics(y_test,preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37feb17d",
   "metadata": {},
   "source": [
    "### Create \"Results\" dataframe of test data\n",
    "This will combine the original X_test and y_test data into a new dataframe as well as creating  'model_preds' and 'pred_probability' columns from GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e0fda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Results dataframe\n",
    "Results = pd.DataFrame.copy(X_test)\n",
    "# Add loan_status column\n",
    "Results['loan_status'] = y_test.copy()\n",
    "# Add model prediction column\n",
    "Results['model_preds'] = preds.copy()\n",
    "# Add prediction probability column\n",
    "Results['pred_probability'] = pred_proba[:,1:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fca2337",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_1 = Results[Results['loan_status']==1][['pred_probability']]\n",
    "pred_0 = Results[Results['loan_status']==0][['pred_probability']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284ba128",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12, 5), facecolor='white')\n",
    "\n",
    "plt.title('Distribution of Prediction Probabilities', size=35, pad=25)\n",
    "plt.hist(pred_0, bins=20, alpha=.5, label='Actual Bad')\n",
    "plt.hist(pred_1, bins=20, alpha=.5, label='Actual Good')\n",
    "plt.axvline(.5, color='red')\n",
    "plt.axvline(.95, color='green')\n",
    "plt.xlabel('Predicted Probability that loan is good', size=20)\n",
    "plt.ylabel('Number of Loans', size=20)\n",
    "plt.xticks(list(np.arange(0,1.05,.05)))\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54a4179",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12, 5), facecolor='white')\n",
    "\n",
    "plt.ylim(0,17500)\n",
    "plt.title('Zoomed in on Probability < .95', size=35, pad=25)\n",
    "plt.hist(pred_0, bins=20, alpha=.5, label='Actual Bad')\n",
    "plt.hist(pred_1, bins=20, alpha=.5, label='Actual Good')\n",
    "plt.axvline(.5, color='red')\n",
    "plt.axvline(.95, color='green')\n",
    "plt.xlabel('Predicted Probability that loan is good', size=20)\n",
    "plt.ylabel('Number of Loans', size=20)\n",
    "plt.xticks(list(np.arange(0,1.05,.05)))\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9f9393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentage of loans predicted good under main model\n",
    "round(Results['model_preds'].sum()/len(Results),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58c9274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display head of Results dataframe\n",
    "Results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301ce170",
   "metadata": {},
   "source": [
    "### Create Dataframe of mid-range probability loans\n",
    "This dataframe is comprised of the loans that fall in a more questionable range of the 'pred_probability' column. These loans may be worth having a human underwriter examine further. Run classification metrics on this data to confirm that it is in fact questionable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5803c116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data for loans with mid-range probabilities\n",
    "Questionable = Results[Results['pred_probability'].between(.25,.95)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59464fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate percentage of X_test contained in \"Questionable\"\n",
    "round(len(Questionable)/len(Results),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d25264c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "conf_mat(Questionable['loan_status'],Questionable['model_preds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de322d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Confusion Matrix\n",
    "plot_cm(Questionable['loan_status'],Questionable['model_preds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c799460",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_metrics(Questionable['loan_status'],Questionable['model_preds'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3192c90e",
   "metadata": {},
   "source": [
    "### Create Dataframe of \"solid decision\" loans\n",
    "This dataframe should contain all loans that are in the Results dataframe but not in the \"Questionable\" dataframe. The model should be sufficient at predicting these loans to the point that it would be cost effective to forego further analysis by human underwriters and rely on the model to approve/deny loan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c9d524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data for laons with more certain probabilities\n",
    "Solid = Results[Results['pred_probability'].between(.25,.95)==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ef357a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate percentage of X_test contained in \"Solid\"\n",
    "round(len(Solid)/len(Results),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b6ecdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "conf_mat(Solid['loan_status'],Solid['model_preds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870c66d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "plot_cm(Solid['loan_status'],Solid['model_preds'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1316cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_metrics(Solid['loan_status'],Solid['model_preds'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3fde5b",
   "metadata": {},
   "source": [
    "### Adjust model to decrease Type 1 errors\n",
    "Pursuant to Histogram of Results['pred_probability'] that shows a vast majority of loans scoring >=.95 and a desire to prioritize avoiding the approval of loans that go bad, changing the binary 'model_preds' column from a pred_probability score threshold of .5 as the determining score to a score of .95 will improve Precision Score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d6079f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type 1 error minimizing Dataframe\n",
    "bad_bias = pd.DataFrame.copy(Results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cbad03",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_bias['model_preds'] = [1 if x>=.95 else 0 for x in bad_bias['pred_probability']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9108d07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentage of loans predicted \"good\" under bad_bias\n",
    "round(bad_bias['model_preds'].sum()/len(bad_bias),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef259bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "conf_mat(bad_bias['loan_status'],bad_bias['model_preds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619a9462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "plot_cm(bad_bias['loan_status'],bad_bias['model_preds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e263ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_metrics(bad_bias['loan_status'],bad_bias['model_preds'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f37821",
   "metadata": {},
   "source": [
    "# Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a32dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28b05be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results dataframe to csv\n",
    "Results.to_csv('./data/model_results_df', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b27f97",
   "metadata": {},
   "source": [
    "# References:\n",
    "1. Lenders Club 2007-2018 (by Nathan George) - https://www.kaggle.com/wordsforthewise/lending-club?select=accepted_2007_to_2018Q4.csv.gz\n",
    "2. Data Dictionary - https://www.kaggle.com/wordsforthewise/lending-club/discussion/170691\n",
    "3. Cleaning Tips - https://www.dataquest.io/blog/machine-learning-preparing-data/\n",
    "4. What is a 'trade' - https://www.thepennyhoarder.com/investing/lending-club-note-trading/\n",
    "5. Subgrade order - https://www.lendingclub.com/foliofn/rateDetail.action\n",
    "6. Datetime Conversion 1 - https://stackoverflow.com/questions/2265357/parse-date-string-and-change-format\n",
    "7. Datetime Conversion 2 - https://stackoverflow.com/questions/9504356/convert-string-into-date-type-on-python\n",
    "8. initial_list_status column definitions - https://www.lendacademy.com/lending-club-whole-loan-program-one-year-later/\n",
    "9. GradientBoostingClassifier - https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html\n",
    "10. Plotting ROC curve - https://www.youtube.com/watch?v=uVJXPPrWRJ0\n",
    "11. sns.distplot - https://git.generalassemb.ly/DSIR-412/lesson-classification-metrics-ii\n",
    "12. Confusion Matrix - https://stackoverflow.com/questions/19233771/sklearn-plot-confusion-matrix-with-labels\n",
    "13. Confusion Matrix - https://stackoverflow.com/questions/3529666/matplotlib-matshow-labels\n",
    "14. Confusion Matrix - https://stackoverflow.com/questions/17022154/changing-matshow-xticklabel-position-from-top-to-bottom-of-the-figure\n",
    "15. Dataframe Copy - https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.copy.html\n",
    "16. List Copy - https://www.w3schools.com/python/python_ref_list.asp\n",
    "17. Confusion Matrix - https://stackoverflow.com/questions/21712047/matplotlib-imshow-matshow-display-values-on-plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deccd84b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
